---
title: "Eisenzeit_Digital"
author: "EZD Team"
date: "20 May 2019"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.width = 14, dpi = 300)
library(GWmodel)
library(dplyr)
library(stringr)
library(raster)
library(ggplot2)
library(dismo)
library(maptools)
library(rgdal)
library(ggmap)
library(readr)
library(Deducer)
library(broom)
library(stats)
set.seed(12345)
options(digits = 5, scipen = 100)
```

# Data Processing

## Presence Data
### Load Data
```{r,eval=FALSE}
presence <- read.csv("Daten/fender_2017_lk.csv", dec = ",", header = TRUE) 

# Setting the right classes
for(cols in colnames(presence)) {
  if(class(presence[, cols]) == "integer") {
    presence[, cols] <- as.numeric(presence[, cols])
  }
}
presence$lng_wgs84 <- as.numeric(as.vector(presence$lng_wgs84))
presence$lat_wgs84 <- as.numeric(as.vector(presence$lat_wgs84))

# Transforming some variables

presence$Höhe_SRTM1_puffer50m <- presence$Höhe_SRTM1_puffer50m/100
presence$Wasser_puffer50m <- presence$Wasser_puffer50m/1000
presence$Loess_1zu500k_puffer50m <- presence$Loess_1zu500k_puffer50m/1000

```
### Creating Variable Epoche
```{r,eval=FALSE}
# Merge Epochen
presence <- presence %>%
  mutate(Epoche = if_else(Zeitstellung %in% c("Frühbronzezeit", "Bronzezeit", "Spätbronzezeit", "Mittelbronzezeit", "Urnenfelderzeit"
                                              , "Urnenfelderzeit, ältere", "Urnenfelderzeit, jüngere", "Metallzeit"),
                          "Bronzezeit", 
                          if_else(Zeitstellung %in% c("Hallstattzeit",  "Hallstattzeit, spät", "Hallstattzeit, früh", "Eisenzeit"),
                                  "Eisenzeit",
                                  if_else(Zeitstellung %in% c("Latènezeit", "Frühlatènezeit", "Spätlatènezeit", "Mittellatènezeit", "jüngere Latènezeit"),
                                          "Eisenzeit",
                                          if_else(Zeitstellung %in% c("Altpaläolithikum", "Mittelpaläolithikum", "Jungpaläolithikum", "Endpaläolithikum", "Paläolithikum", 
                                                                      "Spätpaläolithikum" ),
                                                  "Paläolithikum",
                                                  if_else(Zeitstellung %in% c("Endneolithikum", "Glockenbecherkultur", "Großgartacher Kultur", "Linearbandkeramik", "Michelsberger Kultur"
                                                                              , "Mittelneolithikum", "Mondsee Gruppe", "Münchshöfener Kultur", "Neolithikum", "Oberlauterbach", "Polling",
                                                                              "Rössener Kultur", "Schnurkeramik", "Schussenrieder Gruppe", "SOB","Spätneolithikum", "Stichbandkeramik",
                                                                              "Altheimer Gruppe", "Chamer Kultur", "Jungneolithikum")
                                                          , "Neolithikum", "Mesolithikum"))))))

# Delete mixed coordinates
presence <- presence[,!colnames(presence) %in% c("wkb_geom", "wkb_geom_wgs84")]

# Creating a binary variable for Siedlung
presence$Siedlung <- ifelse(presence$Typ %in% c("Abri", "Abschnittsbefestigung", "Freilandstation", "Herrenhof", "Höhensiedlung", "Höhensiedlung, befestigt", "Siedlung", "Siedlung, befestigt", "Oppidum", "Ringwall", "Kreisgraben"), TRUE, FALSE)

saveRDS(presence, "Daten/presence.RDS")
```

## Raster Data

### Raster for Bavaria

- Extract Bavaria Shape from Spatial Germany
```{r eval=FALSE}
ger_file <- getData("GADM", country = "Germany", level = 1)
bay_file <- ger_file[match(toupper("Bayern"),toupper(ger_file$NAME_1)),]
```

- Create a Random Raster Over the Space    
```{r eval=FALSE}
bay_raster <- raster(xmn = 8.975, xmx = 13.84167, ymn = 47.26667, ymx = 50.56667, nrow = 396, ncol = 584)
bay_raster[] <- runif(396*584)
```

- Create Mask
```{r eval=FALSE}
bay_mask <- mask(bay_raster, bay_file)
```

### Data Acquisition

#### Height

- Load Data
```{r eval=FALSE}
height <- getData(name = "alt", country = "Germany")
```

- Change Layer Name
```{r eval=FALSE}
names(height) <- "height"
```

- Cut Bavaria Shape
```{r eval=FALSE}
height <- crop(height, bay_mask)
height <- mask(height, bay_mask)
```

- Save Raster
```{r eval=FALSE}
writeRaster(height, "Daten/Raster/height_raster")
```

#### Temperature and Rain

- Load Data
```{r eval=FALSE}
weatherdata <- getData("worldclim", var = "bio", res = 0.5, lon =  12.101624, lat = 49.013432)
weatherdata <- weatherdata[[c(1, 12)]]
```

- Change Name
```{r eval=FALSE}
names(weatherdata) <- c("temp", "rain")
```

- Cut Bavaria Shape
```{r eval=FALSE}
weatherdata <- crop(weatherdata, bay_mask)
weatherdata <- mask(weatherdata, bay_mask)
weatherdata <- stack(weatherdata[[1]] / 10, weatherdata[[2]])
```

- Save Raster
```{r eval=FALSE}
writeRaster(weatherdata[[1]], "Daten/Raster/temp_raster")
writeRaster(weatherdata[[2]], "Daten/Raster/rain_raster")
```

#### Slope, Aspect, Tpi

- Load Data
```{r eval=FALSE}
env_data <- terrain(height, opt = c("slope", "aspect", "tpi"), unit = "degrees")
```

- Turn into Cathegorial Variable
```{r eval=FALSE}
env_data$aspect <- ceiling((env_data$aspect + 360/8/2)/(360/8))
env_data$aspect[env_data$aspect > 8] <- 1
```

- Cut Bavaria Shape
```{r eval=FALSE}
env_data <- crop(env_data, bay_mask)
env_data <- mask(env_data, bay_mask)
```

- Save Raster
```{r eval=FALSE}
writeRaster(env_data[[1]], "Daten/Raster/tpi_raster")
writeRaster(env_data[[2]], "Daten/Raster/slope_raster")
writeRaster(env_data[[3]], "Daten/Raster/aspect_raster")
```

#### Water Distance
(Source: https://biogeo.ucdavis.edu/data/diva/wat/DEU_wat.zip)

- Load Shapefiles
```{r eval=FALSE}
river_shape <- shapefile("Daten/Raster/RawFiles/DEU_water_lines_dcw.shx")
lake_shape <- shapefile("Daten/Raster/RawFiles/DEU_water_areas_dcw.shx")
```

- Create Water Rasters
```{r eval=FALSE}
river_raster <- mask(bay_raster, river_shape)
lake_raster <- mask(bay_raster, lake_shape)
```

- Calculate Distance to Rivers and Lakes
```{r eval=FALSE}
distance_river <- distance(river_raster)
distance_lake <- distance(lake_raster)
```

- Minimum of Distance to Rivers and Distance to Lakes is Distance to Water
```{r eval=FALSE}
distance_water <- min(distance_lake, distance_river)
```

- Save Raster Files
```{r eval=FALSE}
writeRaster(distance_river, "Daten/Raster/RawFiles/river")
writeRaster(distance_lake, "Daten/Raster/RawFiles/lake")
writeRaster(distance_water, "Daten/Raster/RawFiles/water")
```

- Change Name
```{r eval=FALSE}
names(distance_water) <- "distance_water"
```

- Cut Bavaria Shape
```{r eval=FALSE}
distance_water <- mask(distance_water, bay_mask)
```

- Save Raster
```{r eval=FALSE}
writeRaster(distance_water, "Daten/Raster/distance_water_raster")
```

#### Loess Distance
(Source: https://www.lfu.bayern.de/umweltdaten/geodatendienste/pretty_downloaddienst.htm?dld=gk500)

- Load Shapefiles
```{r eval=FALSE}
loess_shape <- shapefile("Daten/Raster/RawFiles/Loess/gk500_haupteinheiten_epsg4258.shx")
```

- Subsetting for Loess
```{r eval=FALSE}
loess_shape <- loess_shape[str_detect(loess_shape$kurztext, "Löß"),]
```

- Create Loess Raster
```{r eval=FALSE}
loess_raster <- mask(bay_raster, loess_shape)
```

- Calculate Distance to Loess Sediments
```{r eval=FALSE}
distance_loess <- raster::distance(loess_raster)
```

- Change Name
```{r eval=FALSE}
names(distance_loess) <- "distance_loess"
```

- Save Raster File
```{r eval=FALSE}
writeRaster(distance_loess, "Daten/Raster/RawFiles/loess")
```

- Cut Bavaria Shape
```{r eval=FALSE}
distance_loess <- mask(distance_loess, bay_mask)
```

- Save Final Raster
```{r eval=FALSE}
writeRaster(distance_loess, "Daten/Raster/distance_loess_raster")
```

#### Frostdays
(Source: https://maps.dwd.de/geoserver/web/wicket/bookmarkable/org.geoserver.web.demo.MapPreviewPage?0)

- Import Data
```{r eval=FALSE}
frostdays <- raster("Daten/Raster/RawFiles/dwd-Frostdays_annual_map_normals_1971_30.tif")
```

- Change Name
```{r eval=FALSE}
names(frostdays) <- "frostdays"
```

- Change Coordinates to WGS
```{r eval=FALSE}
frostdays <- projectRaster(frostdays, crs = crs(bay_mask))
```

- Data in Bavaria Shape
```{r eval=FALSE}
frostdays <- resample(frostdays, bay_mask)
frostdays <- mask(frostdays, bay_mask)
```

- Save Final Raster
```{r eval=FALSE}
writeRaster(frostdays, "Daten/Raster/frostdays_raster")
```

- Load Final Raster
```{r eval=FALSE}
# frostdays <- raster("Daten/Raster/frostdays_raster.grd")
```


#### Sunhours
(Source: https://maps.dwd.de/geoserver/web/wicket/bookmarkable/org.geoserver.web.demo.MapPreviewPage?0)

- Import Data 
```{r eval=FALSE}
sunhours <- raster("Daten/Raster/RawFiles/dwd-SDMS_17_1971_30.tif")
```

- Change Name
```{r eval=FALSE}
names(sunhours) <- "sunhours"
```

- Change Coordinates to WGS
```{r eval=FALSE}
sunhours <- projectRaster(sunhours, crs = crs(bay_mask))
```

- Data in Bavaria Shape
```{r eval=FALSE}
sunhours <- resample(sunhours, bay_mask)
sunhours <- mask(sunhours, bay_mask)
```

- Save Final Raster
```{r eval=FALSE}
writeRaster(sunhours, "Daten/Raster/sunhours_raster")
```

- Load Final Raster
```{r eval=FALSE}
# sunhours <- raster("Daten/Raster/sunhours_raster.grd")
```

#### Corine
(Source: https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download)

- Import Data
```{r eval=FALSE}
corine <- raster("Daten/Raster/RawFiles/CLC2012_CLC2006_V2018_20b2.tif")
```

- Change Name
```{r eval=FALSE}
names(corine) <- "corine"
```

- Change Coordinates to WGS
```{r eval=FALSE}
corine <- projectRaster(corine, bay_mask)
```

- Save Raster File
```{r eval=FALSE}
writeRaster(corine, "Daten/Raster/RawFiles/corine")
```

- Data in Bavaria Shape
```{r eval=FALSE}
corine <-  mask(corine, bay_mask)
```

- Save Final Raster
```{r eval=FALSE}
writeRaster(corine, "Daten/Raster/corine_raster")
```

### Stack File with Raster Data

- Load all Predictors
```{r}
predictors <- stack(c(
  "Daten/Raster/height_raster.grd",
  "Daten/Raster/temp_raster.grd",
  "Daten/Raster/rain_raster.grd",
  "Daten/Raster/distance_water_raster.grd",
  "Daten/Raster/distance_loess_raster.grd",
  "Daten/Raster/frostdays_raster.grd",
  "Daten/Raster/sunhours_raster.grd",
  "Daten/Raster/corine_raster.grd",
  "Daten/Raster/tpi_raster.grd",
  "Daten/Raster/slope_raster.grd",
  "Daten/Raster/aspect_raster.grd"))
```

- Transformed Stack
```{r}
predictors <- stack(c(
  predictors[[1]]/100,
  predictors[[2]],
  predictors[[3]],
  predictors[[4]]/1000,
  predictors[[5]]/1000,
  predictors[[6]],
  predictors[[7]],
  predictors[[8]],
  predictors[[9]],
  predictors[[10]],
  predictors[[11]]
  ))
```

- Plot Rasters
```{r}
plot(predictors[[1]], main = "height")
plot(predictors[[2]], main = "temp")
plot(predictors[[3]], main = "rain")
plot(predictors[[4]], main = "distance_water")
plot(predictors[[5]], main = "distance_loess")
plot(predictors[[6]], main = "frostdays")
plot(predictors[[7]], main = "sunhours")
plot(predictors[[8]], main = "corine")
plot(predictors[[9]], main = "tpi")
plot(predictors[[10]], main = "slope")
plot(predictors[[11]], main = "aspect")
```

## Negative Data

## Create Dataset with Presence and Negative Data Using Raster Data
- Defining Variable Names to keep.
```{r}
cols2keep_negative <- c("lon", "lat", "w.dist", "temp", "rain", "slope", "tpi", "aspect")
cols2keep_raw <- c("Typ", "Zeitstellung", "Epoche")
cols2keep <- c(names(predictors), "lon", "lat")


# Deleting duplicated coordinates to avoid overestimating that point
presence <- readRDS("Daten/presence.RDS")
raw_data <- presence[!duplicated(presence[,c("lng_wgs84", "lat_wgs84", "DenkmalNummer", "Epoche")]),]

# Delete unnecessary columns and order by coordinates
raw_data <- raw_data[,!colnames(raw_data) %in% c("lng", "lat", "wkb_geom", "wkb_geom_wgs84")]
raw_data <- raw_data[order(raw_data$lng_wgs84, raw_data$lat_wgs84),]
```
- Extracting Variables from Raster Data by Presence Coordinates.
```{r}
data_coords <- dplyr::select(raw_data, lng_wgs84, lat_wgs84)
df_data <- raster::extract(predictors, data_coords)

presence_raster <- na.omit(cbind(df_data, data_coords, raw_data[, cols2keep_raw]))
presence_raster$Epoche <- as.factor(presence_raster$Epoche)
colnames(presence_raster)[colnames(presence_raster) %in% c("lng_wgs84", "lat_wgs84")] <- c("lon", "lat")

# Epoche = Eisenzeit
presence_raster_ez <- presence_raster[presence_raster$Epoche %in% c("Eisenzeit"),]

```
- Negative Data
```{r}
negative <- read.csv("Daten/neg29kfiltered.csv", sep = " ")
negative <- negative[, cols2keep_negative]
negative <- na.omit(negative)
negative$temp <- negative$temp/10
negative$Typ <- NA
```
Setting the same amount of datapoints as number of datapoints in the presence dataset.
```{r}
# All
row.names(negative) <- seq(1, nrow(negative), 1)
index <- as.numeric(rownames(negative))

# Siedlung
index_siedlung <- base::sample(index, nrow(presence_raster_ez[presence_raster_ez$Typ %in% c("Abri", "Abschnittsbefestigung", "Freilandstation", "Herrenhof", "Höhensiedlung", "Höhensiedlung, befestigt", "Siedlung", "Siedlung, befestigt", "Oppidum", "Ringwall", "Kreisgraben"),]))
index <- index[!index %in% index_siedlung]

# Viereckschanze
index_4eckschanze <- base::sample(index, nrow(presence_raster_ez[presence_raster_ez$Typ %in% "Viereckschanze",]))
index <- index[!index %in% index_4eckschanze]
index_ez <- base::sample(index, nrow(presence_raster_ez))
index <- index[!index %in% index_ez]


negative[index_siedlung, "Typ"] <- "Siedlung"
negative[index_4eckschanze, "Typ"] <- "Viereckschanze"
negative[index_ez, "Typ"] <- "Alle"
negative[index, "Typ"] <- "Sonstige"
```

- Extracting Variables from Raster Data by Negative Coordinates.
```{r}
# Alle ----
negative_all_coords <- dplyr::select(negative[negative$Typ %in% "Alle",], lon, lat)
negative_all <- raster::extract(predictors, negative_all_coords)

negative_all <- cbind(negative_all, negative_all_coords)

# Siedlung ----
negative_siedlung_coords <- dplyr::select(negative[negative$Typ %in% "Siedlung",], lon, lat)
negative_siedlung <- raster::extract(predictors, negative_siedlung_coords)

negative_siedlung <- cbind(negative_siedlung, negative_siedlung_coords)

# Viereckschanzen ----
negative_viereckschanze_coords <- dplyr::select(negative[negative$Typ %in% "Viereckschanze",], lon, lat)
negative_viereckschanze <- raster::extract(predictors, negative_viereckschanze_coords)

negative_viereckschanze <- cbind(negative_viereckschanze, negative_viereckschanze_coords)
```

- Merging new presence data with negative data
```{r}
# ALL DATA ----
df_all <- rbind(
  data.frame(presence_raster_ez[,cols2keep], site=TRUE),
  data.frame(negative_all, site=FALSE)
)

df_all <- na.omit(df_all)
#saveRDS(df_all, "Daten/GWGLM/df_all.RDS")

# DATA FOR 'Siedlungen' ----
df_siedlung <- rbind(
  data.frame(presence_raster_ez[presence_raster_ez$Typ %in% c("Abri", "Abschnittsbefestigung", "Freilandstation", "Herrenhof", "Höhensiedlung", "Höhensiedlung, befestigt", "Siedlung", "Siedlung, befestigt", "Oppidum", "Ringwall", "Kreisgraben"), cols2keep], site=TRUE),
  data.frame(negative_siedlung, site=FALSE)
)

df_siedlung <- na.omit(df_siedlung)
#saveRDS(df_siedlung, "Daten/GWGLM/df_siedlung.RDS")


# DATA FOR '4eckschanze' ----
df_viereckschanze <- rbind(
  data.frame(presence_raster_ez[presence_raster_ez$Typ %in% "Viereckschanze", cols2keep], site=TRUE),
  data.frame(negative_viereckschanze, site=FALSE)
)

df_viereckschanze <- na.omit(df_viereckschanze)
#saveRDS(df_viereckschanze, "Daten/GWGLM/df_viereckschanze.RDS")
```

## Descriptive Analysis
### spatial clusters
```{r}
data1 <- mutate(presence, Zeitstellung_num = as.numeric(Zeitstellung))
myLocs <- data1

names(myLocs)[names(myLocs) %in% "lat_wgs84"] <- "Lat"
names(myLocs)[names(myLocs) %in% "lng_wgs84"] <- "Long"


myLocs$Epoche <- if_else(myLocs$Zeitstellung %in% c("Hallstattzeit",  "Hallstattzeit, spät", "Hallstattzeit, früh", "Eisenzeit"),
                                  "Hallstattzeit",
                                  if_else(myLocs$Zeitstellung %in% c("Latènezeit", "Frühlatènezeit", "Spätlatènezeit", "Mittellatènezeit", "jüngere Latènezeit"),
                                          "Latenezeit", 
                                  if_else(myLocs$Epoche %in% c("Mesolithikum", "Paläolithikum"), "Neolithikum", myLocs$Epoche)))

## Karten vorbereiten ----

myLocs <- arrange(myLocs, Zeitstellung_num, Typ)

# emojifont::load.fontawesome() #icons for the different travel types
# fa <- data.frame(LocType = c("Home", "Project", "Meeting", "Travel"),
#                  fnt = fontawesome(c('fa-home', 'fa-coffee', 'fa-plane', 'fa-child')))
# myColors <- c("#e7298a", "#1b9e77", "#8c510a", "#3288bd")
# 
# myLocs <- inner_join(myLocs, fa) #link location list to geocodes
mbound <- c(8, #min/max longitude/latitude to display on the map
            47,
            14,
            51)

bayern_lines <- ggmap::get_stamenmap(bbox = mbound, zoom = 6, crop = T, maptype = "toner-lines")


myLocs$spatial_cluster <- ifelse(myLocs$Siedlung %in% TRUE, "Siedlung", ifelse(myLocs$Typ %in% "Viereckschanze", "Viereckschanze", ifelse(myLocs$Typ %in% c("Bestattung", "Bestattung, Hügelgrab"), "Bestattung", ifelse(myLocs$Typ %in% "Grabenwerk", "Grabenwerk", ifelse(myLocs$Typ %in% "Höhlenfunde", "Höhlenfunde", myLocs$Typ)))))
myLocs$Epoche <- factor(myLocs$Epoche, levels = c("Neolithikum", "Bronzezeit", "Hallstattzeit", "Latenezeit"))

map_year4 <- function() {
  t <- filter(myLocs, spatial_cluster %in% c("Bestattung", "Grabenwerk", "Höhlenfunde", "Siedlung", "Viereckschanze"))
  print({
    ggmap(bayern_lines) + 
      geom_point(data = filter(t, spatial_cluster == "Siedlung"), aes(x = Long, y = Lat, color = spatial_cluster), size = 0.8, alpha = 0.5) +
      geom_point(data = filter(t, spatial_cluster != "Siedlung"), aes(x = Long, y = Lat, color = spatial_cluster), size = 1, alpha = 0.8) +
      #geom_point(data = filter(t, Typ != "Siedlung"), aes(x = Long, y = Lat, color = Typ), size = 2, alpha = 1) +
      scale_color_manual(values = c("#e41a1c", "#377eb8", "#4daf4a", "#a6cee3", "#ff7f00")) +
      theme(axis.line = element_blank(), axis.text.x = element_blank(),
            axis.text.y = element_blank(), axis.ticks = element_blank(),
            axis.title.x = element_blank(), axis.title.y = element_blank()
      ) +
      labs(col = "Fundarten") +
      #facet_grid(.~Epoche)
      facet_wrap(~Epoche)
  })
}

#par(mar = c(0,0,0,0))
#png(paste0("Output/geograf_haufung", ".png"), res = 200, pointsize = 16, units = "in", width = 7, height = 7)
map_year4()
#dev.off()
#par(mar = c(5,4,4,2)+0.1)
```

### Comparison of original presence data and raster data
- Function for Histograms
```{r}
#' histogram and density plots
#'
#' @param presence_data Original data frame containing all old variables and coordinates
#' @param raster_data Data frame containing coordinates from 'presence_data' and new variables
#' @param name Character vector specifying which variables tu use for the plot
#' @param ylim range of y values. default: c(0,1)
#' @param xlim range of x values ranging from min and max values of the variable
#' @param breaks see function 'hist'.

hist.plot <- function(presence_data, raster_data, name, ylim = c(0,1), xlim = c(min(presence_data), max(presence_data)), breaks = "Sturges") {
  hist(presence_data, freq = FALSE, ylim = ylim, xlim = xlim, breaks = breaks, xlab = name, lwd = 2, main = name)
  presence_data <- na.omit(ifelse(presence_data == -Inf | presence_data == Inf, NA, presence_data))
  raster_data <- na.omit(ifelse(presence_data == -Inf | presence_data == Inf, NA, raster_data))
  lines(density(presence_data), col = "blue", lwd = 2)
  lines(density(raster_data), col = "orange", lwd = 2)
  legend("topright", legend = c("Density Function: Raw_Data", "Density Function: Raster", "Histogram of Raw_Data"), col = c("blue", "orange", "black"), cex = 1, bty = "n", lty = 1)
}
```

```{r}
# Height 
hist.plot(presence_data = presence$Höhe_SRTM1_puffer50m, raster_data = presence_raster$height, name = "height in 100m", ylim = c(0,0.6), xlim = c(0,20))
# dev.copy(png, "Output/Descriptive/histogram_height.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Temperature
hist.plot(presence_data = presence$Temperatur_Jahr[presence$Temperatur_Jahr >= 0], raster_data = presence_raster$temp, name = "temperature in °C", xlim = c(0,15), ylim = c(0,2), breaks = 50)
# dev.copy(png, "Output/Descriptive/histogram_temp.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Rain
hist.plot(presence_data = presence$Niederschlag_Jahr, raster_data = presence_raster$rain, name = "rain in mm/qm^3", ylim = c(0,0.01), breaks = 10, xlim = c(0, 1500))
# dev.copy(png, "Output/Descriptive/histogram_rain.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Distance to Water
hist.plot(presence_data = presence$Wasser_puffer50m, raster_data = presence_raster$distance_water, name = "distance_water in km", xlim = c(0,10), ylim = c(0,1.4))
# dev.copy(png, "Output/Descriptive/histogram_distance_water.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Distance to Loess
hist.plot(presence_data = presence$Loess_1zu500k_puffer50m, raster_data = presence_raster$distance_loess, name = "distance_loess in km", xlim = c(0,30), ylim = c(0,0.8), breaks = 100)
# dev.copy(png, "Output/Descriptive/histogram_distance_loess.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Frost Days
hist.plot(presence_data = presence$Frosttage_Jahr, raster_data = presence_raster$frostdays, name = "frostdays", xlim = c(0, 120), breaks = 50)
# dev.copy(png, "Output/Descriptive/histogram_frostdays.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Sun Hours
hist.plot(presence_data = presence$Sonnenstunden_Jahr, raster_data = presence_raster$sunhours, name = "sunhours")
# dev.copy(png, "Output/Descriptive/histogram_sunhours.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

# Slope
hist.plot(presence_data = presence$Neigung_SRTM1_puffer50m, raster_data = presence_raster$slope, name = "slope in °", xlim = c(0,30), ylim = c(0,0.8))
# dev.copy(png, "Output/Descriptive/histogram_slope.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
# dev.off()

```

# Continuity
## Preparation for Continuity
- function to calculate distance and number of settlements 
```{r eval=FALSE}

#' dis_count: Function to calculate the distance and the count of settlements in a 30km radius. In order to project from the third to the second dimension, the haversine distance was used. For the mean value of distances, the arithmetic mean was used.
#'
#' @param code_epo data.frame, filtered by the epoch and type to be calculated   
#'
#' @return data.frame, just like code_epo with two more columns, 29 column with the mean distances and 30 column with the count of settlements

dis_count <- function(code_epo) {
  epo_mean <- NA
  k <- 0
  data <- data
  for (i in 1:nrow(code_epo)) {
    print(i)
    code_epo[i - 1, 29] <- mean(epo_mean)
    code_epo[i - 1, 30] <- k
    epo_mean <- NA
    k = 0
    for (j in 1:nrow(code_epo)) {
      if (distHaversine(
        c(code_epo$lng_wgs84[i], code_epo$lat_wgs84[i]),
        c(code_epo$lng_wgs84[j], code_epo$lat_wgs84[j])
      ) <= 30000) {
        epo_mean[k] <-
          distHaversine(
            c(code_epo$lng_wgs84[i], code_epo$lat_wgs84[i]),
            c(code_epo$lng_wgs84[j], code_epo$lat_wgs84[j])
          )
        k <- k + 1
      }
    }
  }
  names(code_epo)[29] <- "distanz"
  names(code_epo)[30] <- "anzahl"
  return(code_epo)
}
```
- function for coding
```{r eval=FALSE}
#' code: Function to calculate if two settlements from two different epochs are at the same spot. If the two settlements are in the same spot, the column "kodierung" will be set 1, else 0. This Function takes some time to calculate  
#'
#' @param code_epo data.frame, filtered by the epoch and type to be calculated, just like in the dis_count function
#' @param df_naechste_Epoche data.frame, same as code_epo, just for the next epoch
#'
#' @return data.frame, just like code_epo with another column with the encoding
   
code <- function(code_epo, df_naechste_Epoche) {
  vgl_epo <- dplyr::select(code_epo, lng_wgs84, lat_wgs84)
  vgl_n_epo <-
    dplyr::select(df_naechste_Epoche, lng_wgs84, lat_wgs84)
  for (i in 1:nrow(vgl_epo)) {
    code_epo[i, 31] <- 0
    print(i)
    for (j in 1:nrow(vgl_n_epo)) {
      if (all.equal(vgl_epo[i, ], vgl_n_epo[j, ]) == TRUE) {
        code_epo[i, 31] <- 1
      }
      else{
        
      }
      
    }
  }
  names(code_epo)[31] <- "kodierung"
  return(code_epo)
}
```
- Calculation of distance and number of settlements and coding

```{r eval=FALSE}
## total computation time: 5h 2min 52sec
# define settlements
set_typ <- c(
  "Abri",
  "Freilandstation",
  "Siedlung",
  "Abschnittsbefestigung",
  "Höhensiedlung",
  "Höhensiedlung, befestigt",
  "Kreisgraben",
  "Ringwall",
  "Siedlung, befestigt",
  "Höhlenfunde"
)
```
- Palaeolithikum
```{r eval=FALSE}
# computation time dis_count: ~ 1 min 23 s
code_palae <-
  dplyr::filter(presence_raster,
                Epoche %in% "Paläolithikum" &
                  Typ %in% set_typ)
code_palae <- dis_count(code_palae)

Meso <-
  dplyr::filter(presence_raster,
                Epoche %in% "Mesolithikum" &
                  Typ %in% set_typ)
# computation time code: ~ 1h 6min
code_palae <- code(code_palae, Meso)
save(code_palae, file = "code_palae.csv")
```

- Mesolithikum
```{r eval=FALSE}
code_meso <-
  dplyr::filter(presence_raster,
                Epoche %in% "Mesolithikum" &
                  Typ %in% set_typ)
# computation time dis_count: ~ 53 s
code_meso <- dis_count(code_meso)
neo <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Neolithikum" &
      Typ %in% set_typ
  )
# computation time code: ~ 1h 
code_meso <- code(code_meso, neo)
save(code_meso, file = "code_neo.csv")
```

- Neolithikum
```{r eval=FALSE}
code_neo <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Neolithikum" &
      Typ %in% set_typ
  )
# computation time dis_count: ~ 2min 30s
code_neo <- dis_count(code_neo)
bronz <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Bronzezeit" &
      Typ %in% set_typ
  )
# computation time code: ~ 1h 48min
code_neo <- code(code_neo, bronz)
save(code_neo, file = "code_neo.csv")
```

- Bronzezeit
```{r eval=FALSE}
code_bro <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Bronzezeit" &
      Typ %in% set_typ
  )
# computation time dis_count: ~ 2min 22s
code_bro <- dis_count(code_bro)
system.time(dis_count(code_bro[1:100,]))
hall <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Hallstattzeit" &
      Typ %in% set_typ
  )
# computation time code: ~ 37min
code_bro <- code(code_bro, hall)
save(code_bro, file = "code_bro.csv")
load("code_bro.csv")
```

- Hallstattzeit
```{r eval=FALSE}

code_hall <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Hallstattzeit" &
      Typ %in% set_typ
  )
# computation time dis_count: ~ 44s
code_hall <- dis_count(code_hall)
lat <-
  dplyr::filter(
    presence_raster,
    Epoche %in% "Latènezeit" &
      Typ %in% set_typ
  )
# computation time code: ~ 24min
code_hall <- code(code_hall, lat)

```
- Merging
```{r eval=FALSE}
conti <-
  dplyr::bind_rows(code_palae, code_meso, code_neo, code_bro, code_hall)

# record whether all the data has been calculated
nrow(filter(
  presence_raster,
  Epoche %in% c(
    "Hallstattzeit",
    "Bronzezeit",
    "Neolithikum",
    "Mesolithikum",
    "Paläolithikum"
  ) &
    Typ %in% c(
      "Abri",
      "Freilandstation",
      "Siedlung",
      "Abschnittsbefestigung",
      "Höhensiedlung",
      "Höhensiedlung, befestigt",
      "Kreisgraben",
      "Ringwall",
      "Siedlung, befestigt",
      "Höhlenfunde"
    )
)) - nrow(conti)
# 77 were not recorded

```

## Models 
- load the previously calculated data
```{r}
conti <- readRDS(file = "Daten/Konti/Konti.RDS")
conti[which(conti$Epoche == "Paläolithikum"),33] <- 2
conti[which(conti$Epoche == "Mesolithikum"),33] <- 3
conti[which(conti$Epoche == "Neolithikum"),33] <- 4
conti[which(conti$Epoche == "Bronzezeit"),33] <- 5
conti[which(conti$Epoche == "Hallstattzeit"),33] <- 1
names(conti)[33] <- "Epochen_num"
```

### Continuity for all epochs
- Model 
```{r eval = FALSE}
# Continuity for all epochs
# Model with all logical interactions 
conti <- conti[sample(nrow(conti)), ]
conti <- na.omit(conti)
conti_glm <-
  glm(
    as.factor(kodierung) ~ (
      height + slope + aspect + distance_loess + distance_water +
        Umfeldanalyse_km2 + Reliefenergie  + Viewshed_km2)^2 + as.factor(corine) +
        (sunhours + temp + frostdays + rain) ^ 2 +
        distanz + anzahl + tpi + as.factor(Epochen_num) +
        Umfeldanalyse_km2:Reliefenergie + frostdays:rain + height:rain
      ,
      data = conti,
      family = binomial
    )
summary(conti_glm)
```
- Step
```{r eval = FALSE}
conti_glm_step <- step(conti_glm, direction = "both")
summary(conti_glm_step)

# Select the wald test significant parameters
# fitting another glm with the significant parameters
conti_glm <-
  glm(
    as.factor(kodierung) ~ 
      height + aspect + distance_loess + distance_water +
        Umfeldanalyse_km2 + Reliefenergie  + Viewshed_km2 +
      sunhours + temp + frostdays + rain +
      distanz + anzahl + as.factor(Epochen_num) +
      height:Viewshed_km2 + slope:distance_loess + distance_loess:Umfeldanalyse_km2 +
      distance_water:Umfeldanalyse_km2 + Umfeldanalyse_km2:Reliefenergie + sunhours:temp +
      frostdays:rain + height:rain
    ,
    data = conti,
    family = binomial
  )
summary(conti_glm)

# Step
conti_glm_step <- step(conti_glm, direction = "both")
summary(conti_glm_step)


```
- Final Model
```{r}
# ... after fitting the model in this way 4 more times:
# last time fitting the model 
conti <- conti[sample(nrow(conti)), ]
conti <- na.omit(conti)
conti_glm <-
  glm(
    as.factor(kodierung) ~ height + distance_water + 
      Umfeldanalyse_km2 + Reliefenergie + frostdays + rain + distanz + 
      anzahl + as.factor(Epochen_num) + Umfeldanalyse_km2:Reliefenergie + 
      height:rain,
    family = binomial,
    data = conti
  )
summary(conti_glm)

# Step
conti_glm_step <- step(conti_glm, direction = "both")
summary(conti_glm_step)
# Step function no longer throws out parameters
# cor(conti$Umfeldanalyse_km2,conti$Reliefenergie) = -0.75325
# cor(conti$height, conti$rain) = 0.52783
```

- KI for the coefficients
```{r eval = FALSE}
confint(conti_glm)

```

- ROC
```{r}
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
rocplot(conti_glm)+
  ggtitle("ROC for the continuity of all epochs")+
  xlab("False positive rate")+
  ylab("True positive rate")
#dev.copy(png, "../../Output/Konti/conit_ROC.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
#dev.off()
```
- Residual
```{r}
conti_glm <- na.omit(conti_glm)
conti_glm_aug <- augment(conti_glm) %>%
  mutate(index = 1:n()) 
names(conti_glm_aug)[1] <- "Kodierung" 
#par(mar = c(4.5,3.5,3.5,1.5)+0.1)
ggplot(conti_glm_aug, aes(index, .std.resid)) +
  geom_point(aes(color = Kodierung), alpha = .5) +
  ylim(-2, 2)+
  guides(colour = guide_legend(reverse=T))
#dev.copy(png, "../../Output/Konti/conti_res.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
#dev.off()
```
- Probabilities
```{r}
prob_conti <- predict(conti_glm)
prob_conti <- exp(prob_conti)/(1+ exp(prob_conti))
summary(prob_conti)
```

### Continuity for Hallstattzeit
```{r eval = FALSE}
hall <- dplyr::filter(conti, Epoche %in% "Hallstattzeit")
hall <- na.omit(hall)
hall <- hall[sample(nrow(hall)),]
hall_glm <-
  glm(
    as.factor(kodierung) ~ (
      height + slope + aspect + distance_loess + distance_water +
        Umfeldanalyse_km2 + Reliefenergie  + Viewshed_km2
    ) ^ 2 + as.factor(corine) +
      (sunhours + temp + frostdays + rain) ^ 2 +
      distanz + anzahl + tpi + as.factor(Epochen_num) +
      Umfeldanalyse_km2:Reliefenergie + frostdays:rain + height:rain
    ,
    data = conti,
    family = binomial
  )

summary(hall_glm)

```
- Step
```{r eval = FALSE}
hall_glm_step <- step(na.omit(hall_glm), direction = "both")
summary(hall_glm_step)
```
- Final Model
```{r}
hall <- dplyr::filter(conti, Epoche %in% "Hallstattzeit")
hall <- na.omit(hall)
hall <- hall[sample(nrow(hall)),]
# ... after fitting the model as in the upper part 3 more times:
hall_glm <- glm(as.factor(kodierung) ~ height + distance_loess + 
                  distance_water + Umfeldanalyse_km2 + Reliefenergie + frostdays + 
                  rain + distanz + anzahl + Umfeldanalyse_km2:Reliefenergie + 
                  frostdays:rain + height:rain, family = binomial, data = conti)
summary(hall_glm)
# Step
hall_glm_step <- step(na.omit(hall_glm), direction = "both")
summary(hall_glm_step)
# Step function no longer throws out parameters
# cor(hall$Umfeldanalyse_km2, hall$Reliefenergie) = -0.79125
# cor(hall$frostdays, hall$rain) = 0.57090
# cor(hall$height, hall$rain) = 0.66013
```

- KI for the coefficients
```{r eval = FALSE}

confint(hall_glm)

```

- ROC
```{r}
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
rocplot(hall_glm) +
  ggtitle("ROC for the continuity glm of the hallstatt period") +
  xlab("False positive rate") +
  ylab("True positive rate")
#dev.copy(png, "../../Output/Konti/hall_ROC.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
#dev.off()
```
- Residuals
```{r}
hall_glm <- na.omit(hall_glm)
hall_glm_aug <- augment(hall_glm) %>%
  mutate(index = 1:n()) 
names(hall_glm_aug)[1] <- "Kodierung"
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
ggplot(hall_glm_aug, aes(index, .resid)) +
  geom_point(aes(color = Kodierung), alpha = .5) +
  theme_bw() +
  ylim(-2, 2)+
  guides(colour = guide_legend(reverse=T))
#dev.copy(png, "../../Output/Konti/hall_res.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
#dev.off()

```

- probabilities
```{r}
prob_hall <- predict(hall_glm)
prob_hall <- exp(prob_hall)/(1+ exp(prob_hall))
summary(prob_hall)
```



# GLM/GAM
## Functions for GLM
### Loading all required objects

- Shapefiles for rivers and Loess
```{r eval=FALSE}
shapewater <- shapefile("../../Daten/Raster/RawFiles/DEU_water_lines_dcw.shx")
loess_shape <- shapefile("../../Daten/Raster/RawFiles/Loess/gk500_haupteinheiten_epsg4258.shx")
```

- Rasterfiles that are required for sampling points from within Bavaria
```{r eval=FALSE}
ger <- raster::getData(name = "GADM", country = "Germany", level = 1)
ger_alt <- raster::getData(name = "alt", country = "Germany")
```

- The coordinates of Bavarias border will serve as a default border for bavSamp()
```{r eval=FALSE}
bayern_coords <- ger@polygons[[2]]@Polygons[[1]]@coords
```

## Automating Samplingprocess
- Function to sample random points from bavaria

```{r eval=FALSE}
#' bavSamp: Sample random points from within the borders of Bavaria. The Function will run a set amount of iterations until returning a spatial.points.data.frame that contains a random sample of coordinate pairs within Bavaria. The function initializes an empty spatial.points.data.frame that will gradually be filled up with the sampled points. 
#'
#' @param from Raster from which the points are sampled originally.
#' @param within Polygon, borders of region in which the points should fall.
#' @param size Size of coordinate pair sample that gets drawn in every iteration. 
#' @param maxiter Maximum number of iterations the function will run.
#' @param rlength Number of points that should be returned.
#'
#' @return a spatial.points.data.frame
#' @export
#'
#' @examples
bavSamp <- function(from = ger_alt, within = bayern_coords, size = 1000, maxiter = 100, rlength = 100){
  i <- 0
  iteration <- 1
  returnframe <- new("SpatialPoints",   
                     coords = structure(numeric(0), .Dim = c(0L, 2L),                                  .Dimnames = list(NULL, c("coords.x1", "coords.x2"))),  
                     bbox = structure(c(1, 1, 1, 1), .Dim = c(2L, 2L),                                 .Dimnames = list(c("coords.x1", "coords.x2"), c("min", "max"))),
                     proj4string = new("CRS", projargs = NA_character_))
  if (i >= maxiter) {
    warning("Maximum number of iterations reached \n Returning sample.")
    warning("Sampling iterations: ", print(i))
    return(returnframe)    
  }
  while (i < maxiter) {
    print(iteration)
    temp <- sampleRandom(from, size, sp = T)
    checkvector <- point.in.polygon(temp@coords[,1], temp@coords[,2], bayern_coords[,1], bayern_coords[,2])
    checkvector <- as.logical(checkvector)
    temp <- temp[checkvector,]
    returnframe <- union(returnframe, temp)
    iteration <- iteration + 1
    if (nrow(returnframe@coords) >= rlength) {
      returnframe <- returnframe[1:rlength,]
      # set i equal to maxiter to abort sampling process early
      i <- maxiter
    }
  }
  return(returnframe)
}
```
- Function to split data.frames into parts of equal length.
```{r eval=FALSE}
#' Splitframe: Split data.frame into parts of equal length.
#'
#' @param df Input data.frame.
#' @param splits Number of parts to split the data.frame into. Nrow of input data.frame has to be a multiple of splits.
#'
#' @return A list of the split data.frames. Output in the form of a list is here desired, since this function is being called in order to utilize parallelization supplied by the foreach and %dopar% operators. 
#' @export
#'
#' @examples
splitframe <- function(df, splits) {
  if (mod(nrow(df), splits) != 0) {
    stop("nrow is not a multiple of splits")
  }
  pointsliste <- list()
  j <- 0
  for (i in 1:splits) {
    pointsliste[[i]] <- df[(j + 1):(i*(nrow(df)/splits)),]
    j <- j + (nrow(df)/splits)
  }
  return(pointsliste)
}
```
- Function to calculate accurate point distances to the rivershapefile. 
```{r eval=FALSE}
#' pardist2water: Calculating point distances to rivers in parallel. The approach via the foreach and doParallel libraries might be less elegant than the builtin functionality for parallel calculation supplied by R on linux systems, but this code should run independent of operating systems.
#'
#' @param pnts A data.frame containing coordinates.
#' @param shapef The rivershapefile the distances will be calculated to
#' @param splits The amount of splits the splitframe() call will execute.
#' @param workers The amount of workers for parallel computation. For 4 core systems 4 workers seem ideal to reduce overhead by setting up more workers for every thread. For larger datasets or stronger processors a larger workforce would of course be ideal. 
#'
#' @return A dataframe augmented with the desired distances.
#' @export
#'
#' @examples
pardist2water <- function(pnts, shapef = shapewater, splits = 10, workers = 4) {
  pnts <- as.data.frame(pnts)
  # split into equal parts
  pointsliste <- splitframe(pnts, splits)
  registerDoParallel(cores = workers)
  tmp <- foreach(i = 1:splits) %dopar% {
    geosphere::dist2Line(p = pointsliste[[i]], line = shapef)
  }
  # unlist tmp to data.frame
  tmp <- do.call(rbind, tmp)
  # bind results with original points
  tmp <- cbind(pnts, tmp)
  return(tmp)
}
```
- Function to fully automate sampling process for coordinate pairs
```{r eval=FALSE}
#' runValidation: Full automated point sampling and point distance calculation.
#'
#' @param numrows Number of desired points.
#' @param rseed Random seed to make results replicable.
#'
#' @return A data.frame.
#' @export
#'
#' @examples
runValidation <- function(numrows, rseed = 1){
  set.seed(rseed)
  tmp.set <- bavSamp(size = 5000, rlength = numrows)
  tmp.points <- tmp.set@coords
  tmp.points <- as.data.frame(tmp.points)
  tmp.points <- pardist2water(tmp.points, splits = 8, workers = 8)
  write.table(tmp.points, file = "../../Daten/negativdaten50k.csv")
  return(tmp.points)
}
```
## Filtering nonsites
- Importing data sets to work with
```{r eval=FALSE}
sitesdf <- read.table(file = "../../Daten/fenderdistance2water.csv")
nonsitesdf <- read.table(file = "../../Daten/negativdaten50k.csv")
```

- Distance function that will be used to calculate point distances
```{r eval=FALSE}
#' Haversine distance corrects for the curvature of the earth and thus most accurately calculates the distances between two given points 1 and 2. It also runs faster than the euclidian counterpart. 
#'
#' @param lon1 Longitude of point 1.
#' @param lat1 Latitude of point 1.
#' @param lon2 Longitude of point 2.
#' @param lat2 Longitutde of point 2.
#' @param r The radius of the sphere the points are located on. Default case equals the radius of the earth.
#'
#' @return The calculated distance.
#' @export
#'
#' @examples
dist_haversine <- function(lon1, lat1, lon2, lat2, r = 6378.388){
  # r = radius of the sphere the coordinates are located on e.g. the earth
  # calculate distance and return result in km
  temp <- 2*r*asin(sqrt((sin(((lat2 - lat1)*(pi/180))/2))^2 + cos(lat1*(pi/180))*cos(lat2*(pi/180)) * sin((((lon1 - lon2)*(pi/180))/2))^2))
  return(temp)
}
```
- Filter function to remove all points that are too close to the sites.
```{r eval=FALSE}
#' Filters nonsite points that are too close to sites. 
#'
#' @param samplefrom Data.frame that contains nonsites in question.
#' @param checkagainst Data.frame that contains sites to be checked.
#' @param margin Radius in km around sites to remove nonsites from. 
#'
#' @return The samplefrom data.frame without the filtered points.
#' @export
#'
#' @examples
filterbymargin_haversine <- function(samplefrom, checkagainst, margin = 1.5) {
  df <- samplefrom
  df$temporary <- 0
  for (i in 1:nrow(checkagainst)){
    df$temporary <- mapply(dist_haversine, df$lon, df$lat, checkagainst$lon[i], checkagainst$lat[i])
    df <- df[(df$temporary>margin),]
  }
  df$temporary <- NULL
  return(df)
}
```
- Filtering out nonsites that are close than 1.5 km to sites
```{r eval=FALSE}
negative50kfiltered <- filterbymargin_haversine(samplefrom = nonsitesdf, checkagainst = sitesdf, margin = 1.5)
nrow(negative50kfiltered)
write.table(negative50kfiltered, file = "../../Daten/neg29kfiltered.csv")
```

## Loading packages and Data required for modeling
- Loading packages
```{r eval=FALSE}
source("loadpackages.R")
```

```{r eval=FALSE}

```


- Loading the predictor rasterstack
```{r eval=FALSE}
predictors <- stack(c(
  "../../Daten/Raster/height_raster.grd",
  "../../Daten/Raster/temp_raster.grd",
  "../../Daten/Raster/rain_raster.grd",
  "../../Daten/Raster/distance_water_raster.grd",
  "../../Daten/Raster/distance_loess_raster.grd",
  "../../Daten/Raster/frostdays_raster.grd",
  "../../Daten/Raster/sunhours_raster.grd",
  "../../Daten/Raster/corine_raster.grd",
  "../../Daten/Raster/tpi_raster.grd",
  "../../Daten/Raster/slope_raster.grd",
  "../../Daten/Raster/aspect_raster.grd"))
```


- Transforming the rasterstack to units that are easily digested
```{r eval=FALSE}
predictors <- stack(c(
  predictors[[1]]/100,
  predictors[[2]],
  predictors[[3]],
  predictors[[4]]/1000,
  predictors[[5]]/1000,
  predictors[[6]],
  predictors[[7]],
  predictors[[8]],
  predictors[[9]],
  predictors[[10]],
  predictors[[11]]
))
```

- Plotting predictors to verify everything went as planned
```{r eval=FALSE}
plot(predictors)
```

## Preparation of Datasets
- Loading Data into the environment
```{r eval=FALSE}
data_sites <- readRDS("../../Daten/GWGLM/df_all.RDS")
data_settle <- readRDS("../../Daten/GWGLM/df_siedlung.RDS")
data_viereck <- readRDS("../../Daten/GWGLM/df_viereckschanze.RDS")
data_nonsites <- read.table(file = "../../Daten/neg29kfiltered.csv")
```
These sets yet contain unequal amounts of site, and nonsite points
We fix that in the following steps:
- Filtering sites from nonsites
```{r eval=FALSE}
data_sites <- filter(data_sites, site == 1)
data_settle <- filter(data_settle, site == 1)
data_viereck <- filter(data_viereck, site == 1)
```

- Automating extraction of raster data for given coordinates
```{r eval=FALSE}
#' Generate data.frame that is almost ready for modeling.
#'
#' @param sitesdata Data.frame containing site coordinates.
#' @param nonsitesdata Data.Frame containing nonsite coordinates.
#' @param predictorstack Rasterstack to extract variables from.
#'
#' @return Data.Frame that is almost ready for modeling process.
#' @export
#'
#' @examples
generateEvidence <- function(sitesdata, nonsitesdata = data_nonsites, predictorstack = predictors) {
  # selecting site points
  sites_temp <- sitesdata
  sites_temp$lon <- as.numeric(as.vector(sites_temp$lon))
  sites_temp$lat <- as.numeric(as.vector(sites_temp$lat))
  # convert to spatial data in order to extract the predictor values for all points
  coordinates(sites_temp) <- c("lon","lat")
  proj4string(sites_temp) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
  nonsites_temp <- nonsitesdata
  coordinates(nonsites_temp) <- c("lon", "lat")
  proj4string(nonsites_temp) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
  # extracting predictor values for sites and nonsites
  sSP <- SpatialPoints(sites_temp@coords)
  nsSP <- SpatialPoints(nonsites_temp@coords)
  values_sites <- extract(predictorstack, sSP)
  values_nonsites <- extract(predictorstack, nsSP)
  # converting back to data.frame for modeling
  coords_sites <- sites_temp@coords
  coords_sites <- as.data.frame(coords_sites)
  coords_nonsites <- nonsites_temp@coords
  coords_nonsites <- as.data.frame(coords_nonsites)
  
  values_sites <- as.data.frame(values_sites)
  values_nonsites <- as.data.frame(values_nonsites)
  values_sites$site <- 1
  values_nonsites$site <- 0
  values_sites$lon <- coords_sites$lon
  values_sites$lat <- coords_sites$lat
  values_nonsites$lon <- coords_nonsites$lon
  values_nonsites$lat <- coords_nonsites$lat
  # selecting unique settlementpoints
  # filtering out coordinate pairs that are equal
  # based on productindex. The Idea being that small differences in coordinate values maka a large difference in 
  # product results. And distinct pairs that yield the same result in products like (9.2, 49.1) and (49.1, 9.2)
  # are impossible to find in the dataset due to the geographic extent of bavaria. 
  # we also tried generating an index with sums which lead to the exact same amount of unique coordinate pairs.
  values_sites$index <- values_sites$lon * values_sites$lat
  values_sites <- values_sites[!duplicated(values_sites$index), ]
  values_sites$index <- NULL
  # combining everything together to a single data.frame for modeling
  evidence <- rbind(values_sites, values_nonsites)
  evidence <- na.omit(evidence)
  return(evidence)
}
```


- Generating evidence data for all three data sets
```{r eval=FALSE}
evidence_sites <- generateEvidence(sitesdata = data_sites)
evidence_settle <- generateEvidence(sitesdata = data_settle)
evidence_viereck <- generateEvidence(sitesdata = data_viereck)
```


- Automate building of sets with equal counts of site == 1 and site == 0
```{r eval=FALSE}
#' Finalize data for modeling process
#'
#' @param evd Data.frame to process. Containing site and nonsite data in unequal amounts.
#'
#' @return Data.frame containing site and nonsite data in equal amounts.
#' @export
#'
#' @examples
finalizeEvidence <- function(evd){
  siedl_pts <- filter(evd, site == 1)
  nons_pts <- filter(evd, site == 0)
  sz <- nrow(siedl_pts)
  nons_pts_sub <- sample_n(nons_pts, size = sz)
  temp <- rbind(siedl_pts, nons_pts_sub)
  return(temp)
}
```


- Finalizing datasets
```{r eval=FALSE}
set.seed(12345)
evidence_sites <- finalizeEvidence(evd = evidence_sites)
evidence_settle <- finalizeEvidence(evd = evidence_settle)
evidence_viereck <- finalizeEvidence(evd = evidence_viereck)
```


- Checking if everything went as planned
```{r eval=FALSE}
nrow(evidence_sites)
nrow(evidence_settle)
nrow(evidence_viereck)
```


## Fitting models
We fit a full model first to see if the model assumptions of logistic regression hold or if variable transformation or removal is needed.
```{r eval=FALSE}
fit_sites <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                     sunhours + corine + tpi + aspect, 
                   family = binomial(), 
                   data = evidence_sites)
summary_sites <- summary(fit_sites)
summary_sites
```

- Checking if model assumptions hold
```{r eval=FALSE}
probabilities <- predict(fit_sites, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
```


## Logistic regression diagnostics:
- Linearity of predictor variables and logit of outcome
```{r eval=FALSE}
mydata <- evidence_sites %>% 
  dplyr::select_if(is.numeric)
predictors_mydata <- colnames(mydata)
# bind logit and tidy data for plotting
mydata <- mydata %>% 
  mutate(logit = log(probabilities/(1-probabilities))) %>% 
  gather(key = "predictors.mydata", value = "predictor.value", -logit , -lon, -lat, -site)

# creating scatter plots: 
linearityplots <- ggplot(mydata, aes(logit, predictor.value)) +
  geom_point(size = 0.5, alpha = 0.5) + 
  facet_wrap(~predictors.mydata, scales = "free_y") + 
  ylab("Predictor Wert") +
  xlab("Logits") 
  
linearityplots

# Aspect and Corine code are categorical variables.
# As the summary of a model that introduces aspect as a factor of 8 levels shows,
# the variables are no longer of significance thus we decided to drop
# aspect, sunhours and corine code from inputvariables
# Moreover we decided to remove tpi because of lacking linearity
```

- Introducing Sunhours as a factor variable
```{r eval=FALSE}
predictors_factors <- predictors
predictors_factors[[7]] <- round(predictors_factors[[7]])

factor_evidence <- generateEvidence(data_sites, nonsitesdata = data_nonsites, predictorstack = predictors_factors)

fit_sites_factor <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                          height * rain + as.factor(layer), 
                        family = binomial(), 
                        data = factor_evidence)
summary_sites_factor <- summary(fit_sites_factor)
summary_sites_factor
```
As significance levels of above 0.9 indicate, the effects of sunhours are pretty much random. Thus we decided to drop sunhours from the model.

- Introducing an interaction term
```{r eval=FALSE}
fit_sites_nocat <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                         height * rain, 
                       family = binomial(), 
                       data = evidence_sites)
summary_sites_nocat <- summary(fit_sites_nocat)
summary_sites_nocat

```
Both the interaction term itself, and the variable height are now of significance.

- Checking other interactions
```{r eval=FALSE}
fit_sites_interact <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                            temp*rain + temp*frostdays + temp*rain*frostdays + rain*frostdays, 
                          family = binomial(), 
                          data = evidence_sites)
summary(fit_sites_interact)
```
This seems to reduce both interpretability of the resulting model and significance of the other variables.
Given that our goal was to produce predictive maps the interpretability of the models may not be of utmost importance, but the predictive performance of the model as measured by the AUROC only improved by 0.005 for this particular model as compared to the model containing just one interaction term. For these reasons, and a lack of distinct domain knowledge of potential interactions between archaeological and climate data, we decided not to introduce more interaction terms to our models.

## Checking model assumptions
- Confusion matrix to assess performance for a naive 0.5 classifier
```{r eval=FALSE}
probabilities <- predict(fit_sites_nocat, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
pred_cl <-  predicted_classes
reference <- ifelse(evidence_sites$site == TRUE, "pos", "neg")
pred_cl <- as.factor(pred_cl)
reference <- as.factor(reference)
# confusion matrix 
caret::confusionMatrix(pred_cl, reference)
```
- Binned residual Plot 
```{r eval=FALSE}
arm::binnedplot(fitted(fit_sites_nocat), 
           residuals(fit_sites_nocat, type = "response"), 
           nclass = 200, 
           xlab = "Expected Values", 
           ylab = "Average Residual", 
           main = "Binned Residual Plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")
```
This looks promising. As a large majority of binned residuals fall into the +-2 Standard deviation confidence band. 


- Checking linearity assumption
```{r eval=FALSE}
mydata <- evidence_sites %>% 
  dplyr::select_if(is.numeric)
predictors_mydata <- colnames(mydata)
# bind logit and tidy data for plotting
mydata <- mydata %>% 
  mutate(logit = log(probabilities/(1-probabilities))) %>% 
  gather(key = "predictors.mydata", value = "predictor.value", -logit , -lon, -lat, -site, -aspect, 
         -corine, -sunhours, -tpi)

# creating scatter plots: 
linearityplots_nocat <- ggplot(mydata, aes(logit, predictor.value)) +
  geom_point(size = 0.5, alpha = 0.5) + 
  # geom_smooth(method = "loess") +
  theme_bw() +
  facet_wrap(~predictors.mydata, scales = "free_y") + 
  ylab("Predictor Wert") +
  xlab("Logits") 
  
linearityplots_nocat
```


Distance water and distance loess might be better represented through smooth terms. Fitting an additive model in the next step.

- Fitting additive model
```{r eval=FALSE}
fit_sites_gam <- gam(site ~ height + temp + rain + frostdays + slope + 
                       height * rain + s(distance_water) + s(distance_loess),
                     family = binomial(),
                     data = evidence_sites)
summary(fit_sites_gam)
plot.gam(fit_sites_gam)
```
The strength of the effects do not seem to be influenced by the distances themselves. Especially distance_water hovers around 0. 

- Analysis of Influential
```{r eval=FALSE}
cookplot <- plot(fit_sites_nocat, which = 4, id.n = 10)
mdl_data <- augment(fit_sites_nocat) %>% 
  mutate(index = 1:n())
# displaying top 10 largest values
topnoutliers <- mdl_data %>% top_n(10, .cooksd)
# plotting standardized residuals
stdresplot <- ggplot(mdl_data, aes(index, .std.resid)) +
  geom_point(aes(color = site), alpha = 0.5) +
  scale_y_continuous(name="Standardized Residuals", limits=c(-3, 5)) +
  theme_bw()
# filtering potential influential data points 
infpoints <- mdl_data %>% 
  filter(abs(.std.resid) > 3)
```
There seem to be 7 influential points. 

- Examination of Multicolinearity
```{r eval=FALSE}
vif <- car::vif(fit_sites_nocat)
vif
```
The Variance inflation factors of height, rain and the interaction term is expected to be high because of that very interaction term we introduced into the model. The other VIFs are smaller than 5 across the board. Everything looks good. 

- Assessing overall classifier performance through AUROC
```{r eval=FALSE}
pROC::auc(pROC::roc(evidence_sites$site, fitted(fit_sites_nocat)))
pROC::auc(pROC::roc(evidence_sites$site,fitted(fit_sites_interact)))
```
More beautiful ROC-Plots can be generated with Deducer::rocplot(). The Package Deducer requires rJava to be installed and thus also requires JAVA 11 SKD to be installed on the system. Aditionally it requires a call of Sys.setenv() to set the correct path to java like so: 
```{r eval=FALSE}
Sys.setenv(JAVA_HOME="C:/PATH/TO/JAVA/")
# Generate a nicer ROC-plot
library(Deducer)
Deducer::rocplot(fit_sites_nocat)
```


## Predictive Mapping
- Predictive Map for the full model
```{r eval=FALSE}
env_data_df_full <- as.data.frame(predictors)
pdata <- predict(fit_sites_nocat, newdata = env_data_df_full, type = "response")

x_pred <- predictors
x_pred$pred <- pdata

# predictive plot for linear model
plot(x_pred$pred)
```

- Fitting models for settlements and Viereckschanzen
```{r eval=FALSE}
fit_settle <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                    height * rain, 
                  family = binomial(), 
                  data = evidence_settle)
summary_settle <- summary(fit_settle)
summary_settle

pROC::auc(pROC::roc(evidence_settle$site, fitted(fit_settle)))

arm::binnedplot(fitted(fit_settle), 
                residuals(fit_settle, type = "response"), 
                nclass = 200, 
                xlab = "Expected Values", 
                ylab = "Average Residual", 
                main = "Binned Residual Plot", 
                cex.pts = 0.8, 
                col.pts = 1, 
                col.int = "gray")

fit_viereck <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
                     height * rain, 
                 family = binomial(), 
                 data = evidence_viereck)
summary_viereck <- summary(fit_viereck)
summary_viereck

pROC::auc(pROC::roc(evidence_viereck$site, fitted(fit_viereck)))

arm::binnedplot(fitted(fit_viereck), 
                residuals(fit_viereck, type = "response"), 
                nclass = 50, 
                xlab = "Expected Values", 
                ylab = "Average Residual", 
                main = "Binned Residual Plot", 
                cex.pts = 0.8, 
                col.pts = 1, 
                col.int = "gray")
```

- Assessing Stability of Model Estimators
For each model we have only one set of data points, but through the sampling process of negative datapoints we do have a large selection of nonsite points to choose from. It only seemed reasonable to inspect the stability of the estimated model coefficients through resampling of nonsite datapoints. 
```{r eval=FALSE}
# Start off by making a copy of data_sites for further processing
stability_sites <- data_sites
# Generating evidence like usual
evidence_stability <- generateEvidence(sitesdata = stability_sites)
# Create an empty data.frame to save the estimated model coefficients into
df_stability <- data.frame(matrix(nrow = 500,ncol = length(fit_sites_nocat$coefficients)))
colnames(df_stability) <- names(fit_sites_nocat$coefficients)
# The following loop redraws a new set of negative datapoints in every iteration.
# Then a model mdl gets estimated based on the new dataset.
# The estimated coefficients get saved as the ith row in our data.frame.
# We then print i because my laptop is slow and I want to see the progress.
for (i in 1:nrow(df_stability)) {
  temp <- finalizeEvidence(evidence_stability)
  mdl <- glm(site ~ height + temp + rain + distance_water + distance_loess + frostdays + slope + 
               height * rain, 
             family = binomial(), 
             data = temp)
  df_stability[i,] <- mdl$coefficients
  print(i)
}
head(df_stability)
# We are not interested in the intercept, to keep the boxplots clean we will drop 
# it from the data.frame
df_stability <- df_stability[,2:9]
colnames(df_stability) <- c("height", "temp", "rain", "wdist", "ldist", "frost", "slope", "HR-inter")
require(reshape2)
ggplot(data = melt(df_stability), aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=variable)) + 
  ylab("Coefficient Estimates") +
  xlab("") + 
  theme(legend.position = "none")
```


- visualizing of interaction term
```{r eval=FALSE}
interdata <- evidence_sites
interdata$height_bin <- ifelse(interdata$height > mean(interdata$height), "above avg","below avg")
interdata$rain_bin <- ifelse(interdata$rain > mean(interdata$rain), "above avg","below avg")
interdata$prob <- fitted(fit_sites_nocat)
interdata$type_num <- interdata$site

# plotting interaction
ggplot(interdata, aes(rain, type_num)) +
  geom_point() +
  stat_smooth(aes(rain, prob, col = height_bin), se = F) +
  labs(y = "Pr(site)", title = "site ~ rain varying by height_bin")

ggplot(interdata, aes(height, type_num)) +
  geom_point() +
  stat_smooth(aes(height, prob, col = rain_bin), se = F) +
  labs(y = "Pr(site)", title = "Diabetes ~ height varying by rain")
```

## Methods of Crossvalidation
To estimate the general performance of the classifier we will carry out two different methods of repeated cross validation. 
- Setting up the data, learners, and tasks
```{r eval=FALSE}
coords = evidence_sites[, c("lon", "lat")]
# Select response and predictors to use in the modeling
data = dplyr::select(evidence_sites, -lon, -lat)
# Create task
data$site <- as.logical(data$site)
task = makeClassifTask(data = data, target = "site",
                       positive = "TRUE", coordinates = coords)

# Specify a learner
lrn = makeLearner(cl = "classif.binomial",
                  link = "logit",
                  predict.type = "prob",
                  fix.factors.prediction = TRUE)
# specifying a resampling method (spRepCV)
perf_level = makeResampleDesc(method = "SpRepCV", folds = 5, reps = 100)
```
- Running resampling
```{r eval=FALSE}
set.seed(37)
sp_cv = mlr::resample(learner = lrn, task = task,
                      resampling = perf_level, 
                      measures = mlr::auc)
boxplot(sp_cv$measures.test$auc)

perf_level_std <- makeResampleDesc(method = "RepCV", folds = 5, reps = 100)
std_cv <- mlr::resample(learner = lrn, task = task,
                        resampling = perf_level_std,
                        measures = mlr::auc)
```

- Visualize results of both resampling methods
```{r eval=FALSE}
boxplot(std_cv$measures.test$auc, sp_cv$measures.test$auc)
```


- Visualize the resampling 
```{r eval=FALSE}
resplots <- createSpatialResamplingPlots(task = task, resample = std_cv, crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0", repetitions = 1,
                                         x.axis.breaks = c(8.5, 14.5),
                                         y.axis.breaks = c(47, 51))
resplots[[1]][[1]]
# classic cv 
rdesc = makeResampleDesc("RepCV", folds = 5, reps = 4)
resamp = resample(makeLearner("classif.binomial"), task = task, rdesc)
##
plots.classic = createSpatialResamplingPlots(task = task, resamp, crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0",
                                             repetitions = 2, x.axis.breaks = c(8.5, 14.5),
                                             y.axis.breaks = c(47, 51))
plots.classic[[1]][[3]]
plots.classic[[1]][[1]]
# plotting them all in a grid: 
require("cowplot")
cowplot::plot_grid(plotlist = plots[["Plots"]], ncol = 3, nrow = 1,
                   labels = plots[["Labels"]])
```


# MAXENT

## Preparation for MaxEnt

- Filter for Eisenzeit and different types and select only coordinates
```{r}
# All Types
presence_all <- filter(presence, Epoche %in% c("Eisenzeit"))
presence_all <- presence_all[4:5]

# Siedlung
presence_s <- filter(presence, Epoche %in% c("Eisenzeit")) %>% filter(Siedlung == TRUE)
presence_s <- presence_s[4:5]

# Viereckschanze
presence_v <- filter(presence, Epoche %in% c("Eisenzeit")) %>% filter(Typ == "Viereckschanze")
presence_v <- presence_v[4:5]
```

- Split into training and testing set
```{r}
set.seed(12345)

# All Types
group <- kfold(presence_all, 5)
presence_train_all <- presence_all[group != 1, ]
presence_test_all <- presence_all[group == 1, ]

# Siedlung
group <- kfold(presence_s, 5)
presence_train_s <- presence_s[group != 1, ]
presence_test_s <- presence_s[group == 1, ]

# Viereckschanze
group <- kfold(presence_v, 5)
presence_train_v <- presence_v[group != 1, ]
presence_test_v <- presence_v[group == 1, ]
```

## MaxEnt Model

### All Types

- Fit model
```{r eval=FALSE}
model_maxent_all <- maxent(predictors, presence_train_all,
                           factors = c("corine", "aspect"), 
                           nbg = nrow(presence_train_all), remove.duplicates = T, 
                           args = c("responsecurves"),
                           path = "Output/Maxent_all")
```

- Prediction
```{r eval=FALSE}
pred_maxent_all <- predict(model_maxent_all, predictors)

# Plot Prediction
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
plot(pred_maxent_all, xlab = "lon", ylab = "lat")
dev.copy(png, "Output/Maxent_All/pred.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(pred_maxent_all)

# Plot Prediction Threshold
plot(pred_maxent_all > (threshold(eval_maxent_all)$spec_sens), legend = F, xlab = "lon", ylab = "lat")
legend("topright", legend = c("no site","site"), fill = c("#F2F2F2FF","#00A600FF"), horiz = F, cex = 1, bty = "n")
dev.copy(png, "Output/Maxent_All/threshold.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()
par(mar = c(5,4,4,2) + 0.1)
```

- Evaluation
```{r eval=FALSE}
bg <- randomPoints(predictors, nrow(presence_test_all))
eval_maxent_all <- evaluate(model_maxent_all, p = presence_test_all, a = bg, x = predictors)
threshold(eval_maxent_all)

plot(eval_maxent_all, "ROC")
dev.copy(png, "Output/Maxent_All/roc.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

boxplot(eval_maxent_all)
dev.copy(png, "Output/Maxent_All/boxplot.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(eval_maxent_all)
```

### Siedlung

- Fit Model
```{r eval=FALSE}
model_maxent_s <- maxent(predictors, presence_train_s,
                         factors = c("corine", "aspect"), 
                         nbg = nrow(presence_train_s), remove.duplicates = T, 
                         args = c("responsecurves"),
                         path = "Output/Maxent_s")
```

- Prediction
```{r eval=FALSE}
pred_maxent_s <- predict(model_maxent_s, predictors)

# Plot Prediction
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
plot(pred_maxent_s, xlab = "lon", ylab = "lat")
dev.copy(png, "Output/Maxent_s/pred.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(pred_maxent_s)

# Plot Prediction Threshold
plot(pred_maxent_s > (threshold(eval_maxent_s)$spec_sens), legend = F, xlab = "lon", ylab = "lat")
legend("topright", legend = c("no site","site"), fill = c("#F2F2F2FF","#00A600FF"), horiz = F, cex = 1, bty = "n")
dev.copy(png, "Output/Maxent_s/threshold.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()
par(mar = c(5,4,4,2) + 0.1)
```

- Evaluation
```{r eval=FALSE}
bg <- randomPoints(predictors, nrow(presence_test_s))
eval_maxent_s <- evaluate(model_maxent_s, p = presence_test_s, a = bg, x = predictors)
threshold(eval_maxent_s)

plot(eval_maxent_s, "ROC")
dev.copy(png, "Output/Maxent_s/roc.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

boxplot(eval_maxent_s)
dev.copy(png, "Output/Maxent_s/boxplot.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(eval_maxent_s)
```

### Viereckschanze

- Fit model
```{r eval=FALSE}
model_maxent_v <- maxent(predictors, presence_train_v,
                           factors = c("corine", "aspect"), 
                           nbg = nrow(presence_train_v), remove.duplicates = T, 
                           args = c("responsecurves"),
                           path = "Output/Maxent_v")
```

- Prediction
```{r eval=FALSE}
pred_maxent_v <- predict(model_maxent_v, predictors)

# Plot Prediction
par(mar = c(4.5,3.5,3.5,1.5)+0.1)
plot(pred_maxent_v, xlab = "lon", ylab = "lat")
dev.copy(png, "Output/Maxent_v/pred.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(pred_maxent_v)

# Plot Prediction Threshold
plot(pred_maxent_v > (threshold(eval_maxent_v)$spec_sens), legend = F, xlab = "lon", ylab = "lat")
legend("topright", legend = c("no site","site"), fill = c("#F2F2F2FF","#00A600FF"), horiz = F, cex = 1, bty = "n")
dev.copy(png, "Output/Maxent_v/threshold.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()
par(mar = c(5,4,4,2) + 0.1)
```

- Evaluation
```{r eval=FALSE}
bg <- randomPoints(predictors, nrow(presence_test_v))
eval_maxent_v <- evaluate(model_maxent_v, p = presence_test_v, a = bg, x = predictors)
threshold(eval_maxent_v)

plot(eval_maxent_v, "ROC")
dev.copy(png, "Output/Maxent_v/roc.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

boxplot(eval_maxent_v)
dev.copy(png, "Output/Maxent_v/boxplot.png", res = 200, pointsize = 16, units = "in", width = 14, height = 10)
dev.off()

print(eval_maxent_v)
```

# GWGLM

## Data Acquisition
The model needs a spatial point data frame. Hence, the data frame is transformed into spatial point data frames using the package 'sp'.
```{r}
# Data for all Fundstellen
df_all_gwglm <- na.omit(df_all)
sp::coordinates(df_all_gwglm) <- c("lon", "lat")
sp::proj4string(df_all_gwglm) <- sp::CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")

# Data for Siedlungen only
df_siedlung_gwglm <- na.omit(df_siedlung)
sp::coordinates(df_siedlung_gwglm) <- c("lon", "lat")
sp::proj4string(df_siedlung_gwglm) <- sp::CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")

# Data for Viereckschanzen only
df_viereckschanze_gwglm <- na.omit(df_viereckschanze)
sp::coordinates(df_viereckschanze_gwglm) <- c("lon", "lat")
sp::proj4string(df_viereckschanze_gwglm) <- sp::CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
```

## The GWGLM Model

### Set the model formula with selected variables
```{r, eval = FALSE}
model_formula <- site ~ height + 
                          temp + 
                          rain + 
                          distance_water + 
                          distance_loess + 
                          frostdays + 
                          slope
```

### Set the distance matrix for each type
```{r, eval = FALSE}
dMat_all <- GWmodel::gw.dist(rp.locat = df_all_gwglm@coords, dp.locat = df_all_gwglm@coords)
dMat_siedlung <- GWmodel::gw.dist(rp.locat = df_siedlung_gwglm@coords, dp.locat = df_siedlung_gwglm@coords)
dMat_viereckschanze <- GWmodel::gw.dist(rp.locat = df_viereckschanze_gwglm@coords, dp.locat = df_viereckschanze_gwglm@coords)
```

### Select the best bandwidth size for each type
```{r, eval=FALSE}
bestBW_all <- GWmodel::bw.ggwr(model_formula, 
                                     data = df_all_gwglm, family = "binomial", kernel = "gaussian", approach = "AICc")


bestBW_siedlung <- GWmodel::bw.ggwr(model_formula, 
                                     data = df_siedlung_gwglm, family = "binomial", kernel = "gaussian", approach = "AICc")


bestBW_viereckschanze <- GWmodel::bw.ggwr(model_formula, 
                                     data = df_viereckschanze_gwglm, family = "binomial", kernel = "gaussian", approach = "AICc")
```

### Run a logistic geographically weighted generalized linear model for each type
- All
```{r, eval = FALSE}
modelGGWR_all <- GWmodel::ggwr.basic(model_formula, 
                                           data = df_all_gwglm, family = "binomial",
                                           bw = bestBW_all, 
                                           dMat = dMat_all, maxiter = 25, kernel = "gaussian", cv = FALSE)


sink("Output/GWGLM/All/model_summary_all.txt")
modelGGWR_all
sink()

# create coefficient data frame
summary_tmp <- data.frame(t(do.call(cbind, lapply(modelGGWR_all$SDF@data[,1:8], summary))))
summary_all <- round(data.frame(cbind(GLM = modelGGWR_all$glms$coefficients, summary_tmp)),5)
write.csv(summary_all, "Output/GWGLM/All/model_summary_all.csv")
```

```{r, echo = FALSE}
read.csv("Output/GWGLM/All/model_summary_all.csv")
```

- Siedlung
```{r, eval=FALSE}
modelGGWR_siedlung <- GWmodel::ggwr.basic(model_formula, 
                                           data = df_siedlung_gwglm, family = "binomial",
                                           bw = bestBW_siedlung, 
                                           dMat = dMat_siedlung, maxiter = 25, kernel = "gaussian", cv = FALSE)


sink("Output/GWGLM/Siedlung/model_summary_siedlung.txt")
modelGGWR_siedlung
sink()

# create coefficient data frame
summary_tmp <- data.frame(t(do.call(cbind, lapply(modelGGWR_siedlung$SDF@data[,1:8], summary))))
summary_siedlung <- round(data.frame(cbind(GLM = modelGGWR_siedlung$glms$coefficients, summary_tmp)),5)
write.csv(summary_siedlung, "Output/GWGLM/Siedlung/model_summary_siedlung.csv")
```

```{r, echo = FALSE}
read.csv("Output/GWGLM/Siedlung/model_summary_siedlung.csv")
```

- Viereckschanze
```{r, eval = FALSE}
modelGGWR_viereckschanze <- GWmodel::ggwr.basic(model_formula, 
                                           data = df_viereckschanze_gwglm, family = "binomial",
                                           bw = bestBW_viereckschanze, 
                                           dMat = dMat_viereckschanze, maxiter = 25, kernel = "gaussian", cv = FALSE)


sink("Output/GWGLM/Viereckschanzen/model_summary_viereckschanze.txt")
modelGGWR_viereckschanze
sink()

# create coefficient data frame
summary_tmp <- data.frame(t(do.call(cbind, lapply(modelGGWR_viereckschanze$SDF@data[,1:8], summary))))
summary_viereckschanze <- round(data.frame(cbind(GLM = modelGGWR_viereckschanze$glms$coefficients, summary_tmp)), 5)
write.csv(summary_viereckschanze, "Output/GWGLM/Viereckschanzen/model_summary_viereckschanze.csv")
```

```{r, echo = FALSE}
read.csv("Output/GWGLM/Viereckschanzen/model_summary_viereckschanze.csv")
```

## Plots

### Preparation for the plots 

#### Coefficient Acquisition for each type
```{r, eval = FALSE}
Coeffs_all <- data.frame(df_all_gwglm@data, df_all_gwglm@coords, 
                         Coef_slope = modelGGWR_all$SDF$slope,
                         Coef_height = modelGGWR_all$SDF$height,
                         Coef_temp = modelGGWR_all$SDF$temp,
                         Coef_rain = modelGGWR_all$SDF$rain,
                         Coef_distance_water = modelGGWR_all$SDF$distance_water,
                         Coef_distance_loess = modelGGWR_all$SDF$distance_loess,
                         Coef_frostdays = modelGGWR_all$SDF$frostdays)

Coeffs_siedlung <- data.frame(df_siedlung_gwglm@data, df_siedlung_gwglm@coords, 
                         Coef_slope = modelGGWR_siedlung$SDF$slope,
                         Coef_height = modelGGWR_siedlung$SDF$height,
                         Coef_temp = modelGGWR_siedlung$SDF$temp,
                         Coef_rain = modelGGWR_siedlung$SDF$rain,
                         Coef_distance_water = modelGGWR_siedlung$SDF$distance_water,
                         Coef_distance_loess = modelGGWR_siedlung$SDF$distance_loess,
                         Coef_frostdays = modelGGWR_siedlung$SDF$frostdays)

Coeffs_viereckschanze <- data.frame(df_viereckschanze_gwglm@data, df_viereckschanze_gwglm@coords, 
                         Coef_slope = modelGGWR_viereckschanze$SDF$slope,
                         Coef_height = modelGGWR_viereckschanze$SDF$height,
                         Coef_temp = modelGGWR_viereckschanze$SDF$temp,
                         Coef_rain = modelGGWR_viereckschanze$SDF$rain,
                         Coef_distance_water = modelGGWR_viereckschanze$SDF$distance_water,
                         Coef_distance_loess = modelGGWR_viereckschanze$SDF$distance_loess,
                         Coef_frostdays = modelGGWR_viereckschanze$SDF$frostdays)
```

#### Creating a function to plot results faster
```{r, eval = FALSE}
#' Title
#'
#' @param data A data frame that contains all Coefficient Values and the coordinates
#' @param variable A character string indicating the variable name the plot should be made for
#'
#' @return A location plot indicating the different coefficient values for each coordinate
#' @export
#'
#' @examples
GGWRplot <- function(data, variable, exponential = TRUE) {
  
  if(exponential == TRUE) {
  
  # plot coordinates
  ggplot(data, aes(x=lon,y=lat))+
    
    # colour the points by the value of the coefficient
    geom_point(aes(colour=exp(data[, paste("Coef_", variable, sep = "")])), size = 0.6)+
    
    # selecting the colour
    scale_colour_gradient2(low = "#E6E402FF", mid = "#F2F2F2FF", high = "#00A600FF",midpoint = 1, space = "hex", na.value = "grey50", guide = "colourbar", guide_legend(title="exp(β)"))+
    
    # background colour
    theme(
  panel.background = element_rect(fill = "darkgrey", colour = "black",
                                size = 2, linetype = "solid"),
  
  # Hide panel borders and remove grid lines
  panel.border = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  # Change axis line
  axis.line = element_line(colour = "black")
  )+
    
    # make a title
    ggtitle(paste(variable, unlist(strsplit(deparse(substitute(data)), "_"))[2], sep = "_"))
    
  }
  
  else if(exponential == FALSE) {
    # plot coordinates
  ggplot(data, aes(x=lon,y=lat))+
    
    # colour the points by the value of the coefficient
    geom_point(aes(colour=(data[, paste("Coef_", variable, sep = "")])), size = 0.6)+
    
    # selecting the colour
    scale_colour_gradient2(low = "#E6E402FF", mid = "#F2F2F2FF", high = "#00A600FF",midpoint = 1, space = "hex", na.value = "grey50", guide = "colourbar", guide_legend(title="β"))+
    
    # background colour
    theme(
  panel.background = element_rect(fill = "darkgrey", colour = "black",
                                size = 2, linetype = "solid"),
  
  # Hide panel borders and remove grid lines
  panel.border = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  # Change axis line
  axis.line = element_line(colour = "black")
  )+
    
    # make a title
    ggtitle(paste(variable, unlist(strsplit(deparse(substitute(data)), "_"))[2], sep = "_"))
  }
    
}
```

### Actual Plots

```{r, eval = FALSE}
# All

# height
GGWRplot(Coeffs_all, "height")
dev.copy(png, "Output/GWGLM/All/height_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# temp
GGWRplot(Coeffs_all, "temp")
dev.copy(png, "Output/GWGLM/All/temp_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# rain
GGWRplot(Coeffs_all, "rain")
dev.copy(png, "Output/GWGLM/All/rain_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_water
GGWRplot(Coeffs_all, "distance_water")
dev.copy(png, "Output/GWGLM/All/distance_water_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_loess
GGWRplot(Coeffs_all, "distance_loess")
dev.copy(png, "Output/GWGLM/All/distance_loess_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# frostdays
GGWRplot(Coeffs_all, "frostdays")
dev.copy(png, "Output/GWGLM/All/frostdays_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# slope
GGWRplot(Coeffs_all, "slope")
dev.copy(png, "Output/GWGLM/All/slope_all.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()


# Siedlung

# height
GGWRplot(Coeffs_siedlung, "height")
dev.copy(png, "Output/GWGLM/Siedlung/height_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# temp
GGWRplot(Coeffs_siedlung, "temp")
dev.copy(png, "Output/GWGLM/Siedlung/temp_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# rain
GGWRplot(Coeffs_siedlung, "rain")
dev.copy(png, "Output/GWGLM/Siedlung/rain_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_water
GGWRplot(Coeffs_siedlung, "distance_water")
dev.copy(png, "Output/GWGLM/Siedlung/distance_water_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_loess
GGWRplot(Coeffs_siedlung, "distance_loess")
dev.copy(png, "Output/GWGLM/Siedlung/distance_loess_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# frostdays
GGWRplot(Coeffs_siedlung, "frostdays")
dev.copy(png, "Output/GWGLM/Siedlung/frostdays_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# slope
GGWRplot(Coeffs_siedlung, "slope")
dev.copy(png, "Output/GWGLM/Siedlung/slope_siedlung.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()

# Viereckschanze

# height
GGWRplot(Coeffs_viereckschanze, "height")
dev.copy(png, "Output/GWGLM/Viereckschanzen/height_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# temp
GGWRplot(Coeffs_viereckschanze, "temp")
dev.copy(png, "Output/GWGLM/Viereckschanzen/temp_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# rain
GGWRplot(Coeffs_viereckschanze, "rain")
dev.copy(png, "Output/GWGLM/Viereckschanzen/rain_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_water
GGWRplot(Coeffs_viereckschanze, "distance_water")
dev.copy(png, "Output/GWGLM/Viereckschanzen/distance_water_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# distance_loess
GGWRplot(Coeffs_viereckschanze, "distance_loess")
dev.copy(png, "Output/GWGLM/Viereckschanzen/distance_loess_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# frostdays
GGWRplot(Coeffs_viereckschanze, "frostdays")
dev.copy(png, "Output/GWGLM/Viereckschanzen/frostdays_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
# slope
GGWRplot(Coeffs_viereckschanze, "slope")
dev.copy(png, "Output/GWGLM/Viereckschanzen/slope_viereckschanze.png", res = 200, pointsize = 16, units = "in", width = 7, height = 5)
dev.off()
```


- All

```{r, echo=FALSE}
myFiles_all <- list.files(path = "Output/GWGLM/All", pattern = "*.png")
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[1]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[2]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[3]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[4]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[5]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[6]))
knitr::include_graphics(paste0("Output/GWGLM/All/", myFiles_all[7]))
```

- Siedlung

```{r, echo=FALSE}
myFiles_Siedlung <- list.files(path = "Output/GWGLM/Siedlung", pattern = "*.png")
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[1]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[2]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[3]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[4]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[5]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[6]))
knitr::include_graphics(paste0("Output/GWGLM/Siedlung/", myFiles_Siedlung[7]))
```

- Viereckschanzen

```{r,echo=FALSE}
myFiles_Viereckschanzen <- list.files(path = "Output/GWGLM/Viereckschanzen", pattern = "*.png")
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[1]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[2]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[3]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[4]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[5]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[6]))
knitr::include_graphics(paste0("Output/GWGLM/Viereckschanzen/", myFiles_Viereckschanzen[7]))
```


```{r}
sessionInfo()
```

